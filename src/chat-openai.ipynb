{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "; Chat OpenAI - Interactive Demo with OpenAI Cloud Provider\n",
    "; =========================================================\n",
    "; This file demonstrates using OpenAI's API instead of a local LLM.\n",
    ";\n",
    "; Prerequisites:\n",
    ";   1. Set OPENAI_API_KEY environment variable\n",
    ";   2. Start the MCP server: mcp-proxy acl2-mcp --transport streamablehttp --port 8000 --pass-environment\n",
    ";\n",
    "; Usage:\n",
    ";   cd src\n",
    ";   acl2\n",
    ";   (ld \"chat-openai.lisp\")\n",
    ";   (chat-openai state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "acl2"
    }
   },
   "outputs": [
    {
     "execution_count": 1,
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"ACL2\"\n"
     ]
    }
   ],
   "source": [
    "(in-package \"ACL2\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ";;;============================================================================\n",
    ";;; Load common definitions\n",
    ";;;============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "acl2"
    }
   },
   "outputs": [
    {
     "execution_count": 2,
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TTAG NOTE (for included book): Adding ttag :QUICKLISP from book /home/acl2/books/quicklisp/base.\n",
      "\n",
      "ACL2 Warning [Ttags] in ( INCLUDE-BOOK \"http-json\" ...):  The ttag\n",
      "note just printed to the terminal indicates a modification to ACL2.\n",
      "To avoid this warning, supply an explicit :TTAGS argument when including\n",
      "the book \"/workspaces/verified-agent/src/http-json\".\n",
      "\n",
      "\n",
      "TTAG NOTE (for included book): Adding ttag :QUICKLISP.DEXADOR from book /home/acl2/books/quicklisp/dexador.\n",
      "\n",
      "ACL2 Warning [Ttags] in ( INCLUDE-BOOK \"http-json\" ...):  The ttag\n",
      "note just printed to the terminal indicates a modification to ACL2.\n",
      "To avoid this warning, supply an explicit :TTAGS argument when including\n",
      "the book \"/workspaces/verified-agent/src/http-json\".\n",
      "\n",
      "\n",
      "TTAG NOTE (for included book): Adding ttag :HTTP-JSON from book /workspaces/verified-agent/src/http-json.\n",
      "\n",
      "ACL2 Warning [Ttags] in ( INCLUDE-BOOK \"http-json\" ...):  The ttag\n",
      "note just printed to the terminal indicates a modification to ACL2.\n",
      "To avoid this warning, supply an explicit :TTAGS argument when including\n",
      "the book \"/workspaces/verified-agent/src/http-json\".\n",
      "\n",
      "\n",
      "TTAG NOTE (for included book): Adding ttag :QUICKLISP from book /home/acl2/books/quicklisp/base.\n",
      "\n",
      "TTAG NOTE (for included book): Adding ttag :QUICKLISP.DEXADOR from book /home/acl2/books/quicklisp/dexador.\n",
      "\n",
      "TTAG NOTE (for included book): Adding ttag :HTTP-JSON from book /workspaces/verified-agent/src/http-json.\n",
      "\n",
      "TTAG NOTE (for included book): Adding ttag :LLM-CLIENT from book /workspaces/verified-agent/src/llm-client.\n",
      "\n",
      "TTAG NOTE (for included book): Adding ttag :MCP-CLIENT from book /workspaces/verified-agent/src/mcp-client.\n",
      "Note (from clause-processors/equality): disabling DISJOIN, DISJOIN2,\n",
      "CONJOIN and CONJOIN2.\n",
      "\n",
      "\n",
      "Summary\n",
      "Form:  ( INCLUDE-BOOK \"chat-lib\" ...)\n",
      "Rules: NIL\n",
      "Warnings:  Ttags\n",
      "Time:  1.07 seconds (prove: 0.00, print: 0.00, other: 1.06)\n",
      " \"/workspaces/verified-agent/src/chat-lib.lisp\"\n"
     ]
    }
   ],
   "source": [
    "(include-book \"chat-lib\"\n",
    "              :ttags ((:quicklisp) (:quicklisp.osicat) (:quicklisp.dexador) \n",
    "                      (:http-json) (:llm-client) (:mcp-client)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ";;;============================================================================\n",
    ";;; OpenAI Configuration (uses OPENAI_API_KEY env var)\n",
    ";;;============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "acl2"
    }
   },
   "outputs": [
    {
     "execution_count": 3,
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary\n",
      "Form:  ( DEFCONST *OPENAI-MODEL* ...)\n",
      "Rules: NIL\n",
      "Time:  0.00 seconds (prove: 0.00, print: 0.00, other: 0.00)\n",
      " *OPENAI-MODEL*\n"
     ]
    }
   ],
   "source": [
    "; (defconst *openai-model* \"gpt-5.2\")\n",
    "(defconst *openai-model* \"gpt-5-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "acl2"
    }
   },
   "outputs": [
    {
     "execution_count": 4,
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary\n",
      "Form:  ( DEFCONST *OPENAI-CONFIG* ...)\n",
      "Rules: NIL\n",
      "Time:  0.00 seconds (prove: 0.00, print: 0.00, other: 0.00)\n",
      "\n",
      "Summary\n",
      "Form:  ( MAKE-EVENT (MV-LET ...))\n",
      "Rules: NIL\n",
      "Time:  0.00 seconds (prove: 0.00, print: 0.00, other: 0.00)\n",
      " *OPENAI-CONFIG*\n"
     ]
    }
   ],
   "source": [
    "(make-event\n",
    " (mv-let (erp api-key state)\n",
    "   (getenv$ \"OPENAI_API_KEY\" state)\n",
    "   (declare (ignore erp))\n",
    "   (mv nil\n",
    "       `(defconst *openai-config*\n",
    "          (make-openai-provider-config ,(or api-key \"\") ,*openai-model*))\n",
    "       state)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ";;;============================================================================\n",
    ";;; Main Entry Point\n",
    ";;;============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "acl2"
    }
   },
   "outputs": [
    {
     "execution_count": 5,
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary\n",
      "Form:  ( DEFUN CHAT-OPENAI ...)\n",
      "Rules: NIL\n",
      "Time:  0.00 seconds (prove: 0.00, print: 0.00, other: 0.00)\n",
      " CHAT-OPENAI\n"
     ]
    }
   ],
   "source": [
    "(defun chat-openai (state)\n",
    "  \"Start an interactive chat session with OpenAI gpt-5.2.\n",
    "   Uses OPENAI_API_KEY environment variable for authentication.\"\n",
    "  (declare (xargs :mode :program :stobjs state))\n",
    "  (interactive-chat-loop-with-provider *initial-chat-state* *openai-config* state))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ";;;============================================================================\n",
    ";;; Usage Instructions\n",
    ";;;============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "acl2"
    }
   },
   "outputs": [
    {
     "execution_count": 6,
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OpenAI Chat loaded (model: gpt-5-mini)\n",
      "Run: (chat-openai state)\n",
      "\n",
      " NIL\n"
     ]
    }
   ],
   "source": [
    "(value-triple \n",
    " (cw \"~%OpenAI Chat loaded (model: ~s0)~%Run: (chat-openai state)~%~%\" \n",
    "     *openai-model*))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACL2",
   "language": "acl2",
   "name": "acl2"
  },
  "language_info": {
   "codemirror_mode": "commonlisp",
   "file_extension": ".lisp",
   "mimetype": "text/x-common-lisp",
   "name": "acl2",
   "pygments_lexer": "common-lisp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
